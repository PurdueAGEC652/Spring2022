<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>AGEC 652 - Lecture 4.2</title>
    <meta charset="utf-8" />
    <meta name="author" content="Diego S. Cardoso" />
    <script src="4_2_constrained_optimization_files/header-attrs-2.11/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# AGEC 652 - Lecture 4.2
## Constrained optimization
### Diego S. Cardoso
### Spring 2022

---

exclude: true

```r
if (!require("pacman")) install.packages("pacman")
```

```
## Loading required package: pacman
```

```r
pacman::p_load(
  xaringanthemer, JuliaCall
)

#options(htmltools.dir.version = FALSE)

knitr::opts_hooks$set(fig.callout = function(options) {
  if (options$fig.callout) {
    options$echo &lt;- FALSE
  }

  knitr::opts_chunk$set(echo = TRUE, fig.align="center")
  options
})
```




```julia
using Pkg
Pkg.activate(".")
Pkg.instantiate()
Pkg.add("Ipopt")
```


---

## .blue[Course roadmap]

1. .gray[Intro to Scientific Computing]
2. .gray[Numerical operations and representations]
3. .gray[Systems of equations]
4. **Optimization**
  1. .gold[Unconstrained optimization]
  2. **Constrained optimization** `\(\leftarrow\)` .blue[You are here]
5. Structural estimation


---

class: inverse, center, middle

.footnote[\*These slides are based on Miranda &amp; Fackler (2002), Nocedal &amp; Wright (2006), Judd (1998), and course materials by Ivan Rudik and Florian Oswald.]

---

## Constrained optimization setup

We want to solve 

`$$\min_x f(x)$$`

subject to

`\begin{gather}
  g(x) = 0\\
  h(x) \leq 0
\end{gather}`

where `\(f:\mathbb{R}^n \rightarrow \mathbb{R}\)`, `\(g:\mathbb{R}^n \rightarrow \mathbb{R}^m\)`, `\(h:\mathbb{R}^n \rightarrow \mathbb{R}^l\)`, and `\(f, g\)`, and `\(h\)` are twice continuously differentiable
- We have `\(m\)` *equality constraints* and `\(l\)` *inequality constraints*

---

## Constraint types

Constraints come in two types: equality or inequality

Let's see a an illustration with a single constraint. Consider the optimization problem

$$
\min_x -exp\left(-(x_1 x_2 - 1.5)^2 - (x_2 - 1.5)^2 \right)
$$

subject to `\(x_1 - x_2^2 = 0\)`

- The equality constraint limits solutions along the curve where `\(x_1 = x_2^2\)`

---

## Constraint types

&lt;div align="center"&gt;
  &lt;img src="figures/equality_constraint.png", height=450&gt;
&lt;/div&gt;

---

## Constraint types

The problem can also be formulated with an inequality constraint

$$
\min_x -exp\left(-(x_1 x_2 - 1.5)^2 - (x_2 - 1.5)^2 \right)
$$

subject to `\(-x_1 + x_2^2 \leq 0\)`

--

How would that change feasible set compared to the equality constraint?

---

## Constraint types

&lt;div style="float:right"&gt;
  &lt;img src="figures/inequality_constraint_binding.png", height=400&gt;
&lt;/div&gt;

The feasible set is in blue
- It extends below and to the right

The solution in this case is along the boundaries of the feasible set
- It coincides with the equality constraint
- In those cases, we say the constraint is **binding** or **active** 

---

## Constraint types

&lt;div style="float:right"&gt;
  &lt;img src="figures/inequality_constraint_slack.png", height=400&gt;
&lt;/div&gt;

If the solution is *interior* to the feasible set, we say the constraint is **slack** or **inactive**
- The solution to the constrained optimization problem is the same as the unconstrained one

---

## Solving constrained optimization problems

You may recall from Math Econ courses that, under certain conditions, we can solve a constrained optimization problem by solving instead the corresponding *mixed complementary problem* using the first order conditions

That trick follows from the **Karush-Kuhn-Tucker (KKT) Theorem**

What does it say?

---

## Karush-Kuhn-Tucker Theorem

&gt; If `\(x^*\)` is a local minimizer and the constraint qualification&lt;sup&gt;1&lt;/sup&gt; holds, then there are multipliers `\(\lambda^* \in \mathbb{R}^m\)` and `\(\mu^* \in \mathbb{R}^l\)` such that `\(x^*\)` is a stationary point of `\(\mathcal{L}\)`, the *Lagrangian* 

.footnote[&lt;sup&gt;1&lt;/sup&gt;Constraint qualification, or regularity conditions, can be formulated depending on the nature of the constraint. We tend to overlook those in Economics, though.]


$$
\mathcal{L}(x, \lambda, \mu) = f(x) + \lambda^T g(x) + \mu^T h(x)
$$

- Variables `\(\lambda\)` and `\(\mu\)` are called *Lagrange multipliers* and in Economics have the intepretation of shadow prices

--

How does this theorem help us?

---

## Karush-Kuhn-Tucker Theorem

Put another way, the theorem states that `\(\mathcal{L}_x(x^*, \lambda^*, \mu^*) = 0\)`

--

So, it tell us that `\((x^*, \lambda^*, \mu^*)\)` solve the system

`\begin{gather}
  f_x + \lambda^T g_x + \mu^T h_x = 0 \\
  \mu_i h^i(x) = 0, \; i = 1, \dots, l \\
  g(x) = 0 \\
  h(x) \leq 0 \\
  \mu \leq 0
\end{gather}`


- Subscripts ( `\(_x\)`) denote derivatives w.r.t. `\(x\)` (it's a vector)
- `\(h^i(x)\)` is the `\(i\)`-th element of `\(h(x)\)`

---

## The KKT approach

The KKT theorem gives us a first approach to solving unconstrained optimization problems

- If the problem has box constraints ( `\(a \leq x \leq b\)`), we can solve the corresponding *mixed complementarity problem* `\(CP(f^\prime, a, b)\)` as we saw in unit 3
--

- If constraints are more elaborated and multidimensional, we need to solve a series of nonlinear systems: one for each possible combination of binding inequality constraints
  - This is probably how you learned to solve utility maximization with a budget constraint


---

## The KKT approach

Let `\(\mathcal{I}\)` be the set of `\({1, 2, ..., l}\)` inequality constraints. For a subset `\(\mathcal{P} \in \mathcal{I}\)` of, we define the `\(\mathcal{P}\)` problem as the nonlinear system of equations

`\begin{gather}
  f_x + \lambda^T g_x + \mu^T h_x = 0 \\
  h^i(x) = 0, \; i \in \mathcal{P} \\
  \mu_i = 0, \; i \in \mathcal{I} - \mathcal{P} \\
  g(x) = 0 
\end{gather}`

--

We solve this system for every possible combination of binding constraints `\(\mathcal{P}\)`
- There might not be a solution for some combinations. That's OK
- Compare the solutions of all combinations and pick the optimal (where `\(f\)` attains the smallest value, in this case)

---

## The KKT approach

When we have a good intuition about the problem, we may know ahead of time which constraints will bind
- For example, with monotonically increasing utility functions, we know the budget constraint binds

--

But as the number of constraints grows, we have an even larger number of possible combinations
- More combinations = more nonlinear systems to solve and compare

---

## Other solution approaches

The combinatorial nature of the KKT approach is not that desirable from a computational perspective
- However, if the resulting nonlinear systems are simple to solve, we may still favor KKT

There are computational alternatives to KKT. We'll discuss three types of algorithms

- Penalty methods
- Active set methods
- Interior point methods


---

class: inverse, center, middle

# Constrained optimization algorithms

---

## Penalty methods

Suppose we wish to minimize some function subject to equality constraints (easily generalizes to inequality)
`$$\min_x f(x) \,\,\, \text{s. t.} \,\, g(x) = 0$$`

--

How does an algorithm know to not violate the constraint?

--

One way is to introduce a **penalty function** into our objective and remove the constraint

`$$Q(x;\rho) = f(x) + \rho P(g(x))$$`
where `\(\rho\)` is the penalty parameter

---

## Penalty methods


With this, we transformed it into an unconstrained optimization problem
`$$\min_x Q(x; \rho) = f(x) + \rho P(g(x))$$`
--

How do we pick `\(P\)` and `\(\rho\)`?

--

A first idea is to penalize a candidate solution as much as possible whenever it leaves the feasible set: infinite penalty!

`$$Q(x) = f(x) + \infty \mathbf{1}(g(x) \neq 0)$$`
where `\(\mathbf{1}\)` is an indicator function

- This is the **infinity step** method

---

## Penalty methods

However, the infinite step method is a pretty bad idea

- `\(Q\)` becomes discontinuous and non-differentiable: it's very hard for algorithms to iterate near the region where the constraint binds
- Any really large value or `\(\rho\)` leads to the same practical problem

--

So we might instead use a more forgiving penalty function

---

## Penalty methods

A widely-used choice is the quadratic penalty function

`$$Q(x;\rho) = f(x) + \frac{\rho}{2} \sum_i g_i^2(x)$$`

- For inequality constraint `\(h(x) \leq 0\)`, we can use `\([\max(0, h_i(x))]^2\)` 

--

The second term increases the value of the function
- bigger `\(\rho \rightarrow\)` bigger penalty from violating the constraint

--

The penalty terms are smooth `\(\rightarrow\)` use unconstrained optimization techniques  
to solve the problem by searching for iterates of `\(x_k\)`

---

## Penalty methods

Algorithms generally iterate on sequences of `\(\rho_k \rightarrow \infty\)` as `\(k \rightarrow \infty\)`, to require satisfying the constraints as we close in

--

There are also *Augmented Lagrangian methods* that take the quadratic penalty method and add explicit estimates of Lagrange multipliers to help force binding constraints to bind precisely 

---

## Penalty method example

Example:
`$$\min x_1 + x_2 \,\,\,\,\,\text{      subject to:    } \,\,\, x_1^2 + x_2^2 - 2 = 0$$`

--

Solution is pretty easy to show to be `\((-1, -1)\)`

--

The penalty method function `\(Q(x_1, x_2; \rho)\)` is
`$$Q(x_1, x_2; \rho) = x_1 + x_2 + \frac{\rho}{2} (x_1^2 + x_2^2 - 2)^2$$`

--

Let's ramp up `\(\rho\)` and see what happens to how the function looks

---

## Penalty method example

`\(\rho = 1\)`, solution is around `\((-1.1, -1.1)\)`

&lt;div align="center"&gt;
  &lt;img src="figures/penalty_method_1.png" height=400&gt;
&lt;/div&gt;

---

## Penalty method example

`\(\rho = 10\)`, solution is very close to `\((-1, -1)\)`. Notice how quickly value increases outside `\(x_1^2 + x_2^2 = 2\)` circle

&lt;div align="center"&gt;
  &lt;img src="figures/penalty_method_2.png" height=400&gt;
&lt;/div&gt;


---

## Active set methods

The KKT method can lead to too many combinations of constraints to evaluate

Penalty methods don't have the same problem but still require us to evaluate every constraint, even if they are not binding

-- 

Improving on the KKT approach, **active set methods** strategically to pick a sequence of combinations of constraints

---

## Active set methods

Instead of trying all possible combinations, like in KKT, active set methods start with an initial guess of the binding constraints set

Then, iterate by periodically checking constraints
- Add or keep the ones that are active (binding)
- Drop the ones that are inactive (slack)

--

If an appropriate strategy of picking sets is chosen, active set algorithms converge to the optimal solution
  
---

## Interior point methods

Interior point methods are also called **barrier methods**

--

These are typically used for inequality constrained problems

--

The name **interior point** comes from the algorithm traversing the domain along the interior of the inequality constraints

--

**Issue:** how do we ensure we are on the interior of the feasible set?

--

**Main idea:** impose a **barrier** to stop the solver from letting a constraint bind

---

## Interior point methods

Consider the following constrained optimization problem
`\begin{gather}
	\min_{x} f(x) \notag\\
	\text{subject to:  } g(x) = 0, h(x) \leq 0
\end{gather}`

--

Reformulate this problem as
`\begin{gather}
	\min_{x,s} f(x) \notag\\
	\text{subject to:  } g(x) = 0, h(x) + s = 0, s \geq 0
\end{gather}`

where `\(s\)` is a vector of slack variables for the constraints

---

## Interior point methods

Final step: introduce a **barrier function** to eliminate the inequality constraint,
`\begin{gather}
	\min_{x,s} f(x) - \mu \sum_{i=1}^l log(s_i) \notag\\
	\text{subject to:  } g(x) = 0, h(x) + s = 0
\end{gather}`

where `\(\mu &gt; 0\)` is a barrier parameter

---

## Interior point methods

The barrier function prevents the components of `\(s\)` from approaching zero by imposing a logarithmic barrier `\(\rightarrow\)` it maintains slack in the constraints
- Another common barrier function is `\(\sum_{i=1}^l (1/s_i)\)`

--

Interior point methods solve a sequence of barrier problems until `\(\mu_k\)` converges to zero

--

The solution to the barrier problem converges to that of the original problem

---

class: inverse, center, middle

# Constrained optimization in Julia

---

## Constrained optimization in Julia


&lt;div style="float:right"&gt;
  &lt;img src="figures/van_halen_jump.jpg" height=400&gt;
&lt;/div&gt;

We are going to cover a cool package called `JuMP.jl`
- It offers a whole modeling language inside Julia
- You define your model and plug it into one of the [many solvers available](https://jump.dev/JuMP.jl/stable/installation/#Supported-solvers)
- It's like GAMS and AMPL... *but FREE and with a full-fledged programming language around it*


---

## Constrained optimization in Julia

Most solvers can be accessed directly in their own packages
- Like we did to use `Optim.jl`
- These packages are usually just a Julia interface for a solver programmed in another language

--

But `JuMP` gives us a unified way of specifying our models and switching between solvers

`JuMP` specifically designed for constrained optimization but works with unconstrained too 
- With more overhead relative to using `Optim` or `NLopt` directly

---

## Getting stated with JuMP

There are 5 key steps:

1) Initialize your model and solver: 
- `mymodel = Model(SomeOptimizer)`

--

2) Declare variables (adding any box constraints)
- `@variable(mymodel, x &gt;= 0)`

--

3) Declare the objective function

- If linear: `@objective(mymodel, Min, 12x + 20y)`
- If nonlinear: `@NLobjective(mymodel, Min, 12x^0.7 + 20y^2)`

---

## Getting stated with JuMP

4) Declare constraints
- If linear: `@constraint(mymodel, c1, 6x + 8y &gt;= 100)`
- If nonlinear: `@NLconstraint(mymodel, c1, 6x^2 - 2y &gt;= 100)`

--

5) Solve it
- `optimize!(mymodel)`
- Note the `!`, so we are modifying `mymodel` and saving results in this object

---

## .blue[Follow along!]

Let's use `JuMP` to solve the illustrative problem from the first slides

We will use solver `Ipopt`, which stands for *Interior Point Optimizer*. It's a free solver we can access through package `Ipopt.jl`


```julia
using JuMP, Ipopt;
```

---

## .blue[Follow along: function definition]

Define the function:
$$
\min_x -exp\left(-(x_1 x_2 - 1.5)^2 - (x_2 - 1.5)^2 \right)
$$


```julia
f(x1,x2) = -exp.(-(x1.*x2 - 3/2).^2 - (x2-3/2).^2);
```

---

## .blue[Follow along: initialize model]


Initialize the model for `Ipopt`

```julia
model = Model(Ipopt.Optimizer)
```

```
## A JuMP Model
## Feasibility problem with:
## Variables: 0
## Model mode: AUTOMATIC
## CachingOptimizer state: EMPTY_OPTIMIZER
## Solver name: Ipopt
```

--

You can set optimzer parameters like this
- There are TONS of parameters you can adjust (see the [manual](https://coin-or.github.io/Ipopt/OPTIONS.html))


```julia
# This is relative tol. Default is 1e-8
set_optimizer_attribute(model, "tol", 1e-6) 
```


---

## .blue[Follow along: declare variables]

We will focus on non-negative values 


```julia
@variable(model, x1 &gt;=0)
```

```
## x1
```

```julia
@variable(model, x2 &gt;=0)
```

```
## x2
```

- You could type `@variable(model, x1)` to declare a `\(x_1\)` as a free variable


---

## .blue[Follow along: declare objective]

We will focus on non-negative values 


```julia
@NLobjective(model, Min, f(x1, x2))
```

--

`JuMP` will use autodiff (with `ForwardDiff` package) by default. If you want to use your define gradient and Hessian, you need to "register" the function like this
```
register(model, :my_f, n, f, grad, hessian)
```
- `:my_f` is the name you want to use inside `model`, `n` is the number of variables `f` takes, and `grad` `hessian` are user-defined functions


---

## .blue[Follow along: solving the model]

First, let's solve the (mostly) unconstrained problem
- Not really unconstrained because we defined non-negative `x1` and `x2` 

Checking our model

```julia
print(model)
```

```
## Min f(x1, x2)
## Subject to
##  x1 &gt;= 0.0
##  x2 &gt;= 0.0
```

---

## .blue[Follow along: solving the model]


```julia
optimize!(model)
```

```
## 
## ******************************************************************************
## This program contains Ipopt, a library for large-scale nonlinear optimization.
##  Ipopt is released as open source code under the Eclipse Public License (EPL).
##          For more information visit https://github.com/coin-or/Ipopt
## ******************************************************************************
## 
## This is Ipopt version 3.14.4, running with linear solver MUMPS 5.4.1.
## 
## Number of nonzeros in equality constraint Jacobian...:        0
## Number of nonzeros in inequality constraint Jacobian.:        0
## Number of nonzeros in Lagrangian Hessian.............:        0
## 
## Total number of variables............................:        2
##                      variables with only lower bounds:        2
##                 variables with lower and upper bounds:        0
##                      variables with only upper bounds:        0
## Total number of equality constraints.................:        0
## Total number of inequality constraints...............:        0
##         inequality constraints with only lower bounds:        0
##    inequality constraints with lower and upper bounds:        0
##         inequality constraints with only upper bounds:        0
## 
## iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
##    0 -1.1449605e-02 0.00e+00 1.03e+00   0.0 0.00e+00    -  0.00e+00 0.00e+00   0
##    1 -1.3138288e-02 0.00e+00 5.01e-02  -1.4 4.40e-02    -  1.00e+00 1.00e+00f  1
##    2 -1.4859511e-02 0.00e+00 4.47e-02  -3.4 4.04e-02    -  1.00e+00 1.00e+00f  1
##    3 -1.6966706e-02 0.00e+00 4.95e-02  -4.8 4.45e-02    -  1.00e+00 1.00e+00f  1
##    4 -1.9620344e-02 0.00e+00 5.56e-02  -5.5 4.94e-02    -  1.00e+00 1.00e+00f  1
##    5 -2.3077725e-02 0.00e+00 6.35e-02  -6.3 5.56e-02    -  1.00e+00 1.00e+00f  1
##    6 -2.7794373e-02 0.00e+00 7.43e-02  -6.8 6.35e-02    -  1.00e+00 1.00e+00f  1
##    7 -3.4670094e-02 0.00e+00 9.00e-02  -7.3 7.43e-02    -  1.00e+00 1.00e+00f  1
##    8 -4.5742703e-02 0.00e+00 1.15e-01  -7.8 9.00e-02    -  1.00e+00 1.00e+00f  1
##    9 -6.6634419e-02 0.00e+00 1.62e-01  -8.1 1.15e-01    -  1.00e+00 1.00e+00f  1
## iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
##   10 -1.1847930e-01 0.00e+00 2.76e-01  -8.6 1.62e-01    -  1.00e+00 1.00e+00f  1
##   11 -3.3377241e-01 0.00e+00 6.61e-01  -8.5 2.76e-01    -  1.00e+00 1.00e+00f  1
##   12 -7.4524828e-01 0.00e+00 1.28e+00  -8.5 6.61e-01    -  1.00e+00 1.00e+00f  1
##   13 -9.4053727e-01 0.00e+00 6.18e-01 -11.0 1.28e+00    -  1.00e+00 2.30e-01f  3
##   14 -9.9989242e-01 0.00e+00 3.10e-02  -9.6 9.60e-02    -  1.00e+00 1.00e+00f  1
##   15 -9.9998421e-01 0.00e+00 8.53e-03 -11.0 5.07e-03    -  1.00e+00 1.00e+00f  1
##   16 -9.9999077e-01 0.00e+00 4.17e-03 -11.0 1.04e-03    -  1.00e+00 1.00e+00f  1
##   17 -9.9999761e-01 0.00e+00 3.13e-03 -11.0 1.78e-03    -  1.00e+00 1.00e+00f  1
##   18 -9.9999999e-01 0.00e+00 2.95e-04 -11.0 1.38e-03    -  1.00e+00 1.00e+00f  1
##   19 -1.0000000e+00 0.00e+00 3.32e-06 -11.0 7.45e-05    -  1.00e+00 1.00e+00f  1
## iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
##   20 -1.0000000e+00 0.00e+00 1.33e-07 -11.0 5.74e-07    -  1.00e+00 1.00e+00f  1
## 
## Number of Iterations....: 20
## 
##                                    (scaled)                 (unscaled)
## Objective...............:  -9.9999999999999656e-01   -9.9999999999999656e-01
## Dual infeasibility......:   1.3262150989499029e-07    1.3262150989499029e-07
## Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00
## Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00
## Complementarity.........:   9.9999999999991302e-12    9.9999999999991302e-12
## Overall NLP error.......:   1.3262150989499029e-07    1.3262150989499029e-07
## 
## 
## Number of objective function evaluations             = 27
## Number of objective gradient evaluations             = 21
## Number of equality constraint evaluations            = 0
## Number of inequality constraint evaluations          = 0
## Number of equality constraint Jacobian evaluations   = 0
## Number of inequality constraint Jacobian evaluations = 0
## Number of Lagrangian Hessian evaluations             = 0
## Total seconds in IPOPT                               = 1.074
## 
## EXIT: Optimal Solution Found.
```

---

## .blue[Follow along: solving the model]

The return message is rather long and contains many details about the execution. You can turn this message off with


```julia
set_silent(model);
```

We can check minimizers with




```julia
unc_x1 = value(x1)
```

```
## 1.0000000326687912
```

```julia
unc_x2 = value(x2)
```

```
## 1.4999999423446968
```

```julia
unc_obj = objective_value(model)
```

```
## -0.9999999999999966
```

---

## .blue[Follow along: solving the model]


And the minimum with


```julia
unc_obj = objective_value(model)
```

```
## -0.9999999999999966
```


---

## .blue[Follow along: solving the model]

&lt;div align="center"&gt;
  &lt;img src="figures/jump_ex1.png", height=450&gt;
&lt;/div&gt;


---

## .blue[Follow along: declaring constraints]

Let's add a nonlinear equality constraint `\(-x_1 + x^2 = 0\)` and re-solve the model

```julia
@NLconstraint(model, -x1 +x2^2 == 0)
```

```
## (-x1 + x2 ^ 2.0) - 0.0 == 0
```

```julia
print(model)
```

```
## Min f(x1, x2)
## Subject to
##  x1 &gt;= 0.0
##  x2 &gt;= 0.0
##  (-x1 + x2 ^ 2.0) - 0.0 == 0
```

```julia
optimize!(model)
```

---

## .blue[Follow along: solving the equality constrained model]




```julia
eqcon_x1 = value(x1)
```

```
## 1.3578043097074932
```

```julia
eqcon_x2 = value(x2)
```

```
## 1.1652486042512478
```

```julia
value(-x1 + x2^2) # We can evaluate expressions too
```

```
## 1.9877433032888803e-12
```

```julia
eqcon_obj = objective_value(model)
```

```
## -0.887974742266783
```

---

## .blue[Follow along: solving the equality constrained model]

&lt;div align="center"&gt;
  &lt;img src="figures/jump_ex2.png", height=450&gt;
&lt;/div&gt;

---

## Solving the inequality constrained model

I now initialize a new model with inequality constraint `\(-x_1 + x^2 \leq 0\)`


```julia
model2 = Model(Ipopt.Optimizer);
@variable(model2, x1 &gt;=0);
@variable(model2, x2 &gt;=0);
@NLobjective(model2, Min, f(x1, x2));
@NLconstraint(model2, -x1 + x2^2 &lt;= 0);
optimize!(model2);
```

---

## Solving the inequality constrained model


```julia
ineqcon_x1 = value(x1)
```

```
## 1.357804311747407
```

```julia
ineqcon_x2 = value(x2)
```

```
## 1.165248609391406
```

```julia
ineqcon_obj = objective_value(model2)
```

```
## -0.887974743957088
```

Same results as in the equality constraint: the constraint is binding

---

## Solving the inequality constrained model

&lt;div align="center"&gt;
  &lt;img src="figures/jump_ex3.png", height=450&gt;
&lt;/div&gt;

---

## Relaxing the inequality constraint

What if instead we use inequality constraint `\(-x_1 + x^2 \leq 1.5\)`?


```julia
model3 = Model(Ipopt.Optimizer);
@variable(model3, x1 &gt;=0);
@variable(model3, x2 &gt;=0);
@NLobjective(model3, Min, f(x1, x2));
@NLconstraint(model3, c1, -x1 + x2^2 &lt;= 1.5);
optimize!(model3);
```

---

## Relaxing the inequality constraint


```julia
ineqcon2_obj = objective_value(model3)
```

```
## -1.0
```

```julia
ineqcon2_x1 = value(x1)
```

```
## 1.0000000035503052
```

```julia
ineqcon2_x2 = value(x2)
```

```
## 1.4999999931258383
```

We get the same results as in the unconstrained case

---

## Solving the inequality constrained model

&lt;div align="center"&gt;
  &lt;img src="figures/jump_ex4.png", height=450&gt;
&lt;/div&gt;


---

class: inverse, center, middle

# Practical advice for numerical optimization

---


## Best practices for optimization

Plug in your guess, let the solver go, and you're done right?

--

## WRONG!

--

These algorithms are not guaranteed to always find even a local solution,
you need to test and make sure you are converging correctly

---

## Check return codes

Return codes (or exit flags) tell you why the solver stopped
- There are all sorts of reasons why a solver ends execution
- Each solver has its own way of reporting errors
- In `JuMP` you can use `@show termination_status(mymodel)`

**READ THE SOLVER DOCUMENTATION!**

--

Use trace options to get a sense of what went wrong
- Did guesses grow unexpectedly?
- Did a gradient-based operation fail? (E.g., division by zero)

---

## Check return codes

Examples from [Ipopt.jl documentation](https://coin-or.github.io/Ipopt/OUTPUT.html)

&lt;div align="center"&gt;
  &lt;img src="figures/ipopt_return_codes.png" height=550&gt;
&lt;/div&gt;

---

## Try alternative algorithms

Optimization is approximately 53% art

--

Not all algorithms are suited for every problem `\(\rightarrow\)` it is useful to check how different algorithms perform

--

Interior-point is usually the default in constrained optimization solvers (low memory usage, fast), but try other algorithms and see if the solution generally remains the same

---

## Problem scaling

The **scaling** of a problem matters for optimization performance

--

A problem is **poorly scaled** if changes to `\(x\)` in a certain direction
produce much bigger changes in `\(f\)` than changes to in `\(x\)` in another direction

--

&lt;div align="center"&gt;
  &lt;img src="figures/poorly_scaled.png" height=400&gt;
&lt;/div&gt;

---

## Problem scaling

Ex: `\(f(x) = 10^9 x_1^2 + x_2^2\)` is poorly scaled

--

This happens when things change at different rates:
- Investment rates are between 0 and 1
- Consumption can be in trillions of dollars

--

How do we solve this issue?

--

Rescale the problem: put them in units that are generally within an order of magnitude of 1
- Investment rate in percentage terms: `\(0\%-100\%\)`
- Consumption in units of trillion dollars instead of dollars

---

## Be aware of tolerances

Two main tolerances in optimization:

1. `ftol` is the tolerance for the change in the function value (absolute and relative)
2. `xtol` is the tolerance for the change in the input values (absolute and relative)

--

What is a suitable tolerance?


---

## Be aware of tolerances

It depends

--

Explore sensitivity to tolerance, typically pick a conservative (small) number
- Defaults in solvers are usually `1e-6`

If you are using simulation-based estimators or estimators that depend on successive optimizations, be even more conservative *because errors compound*

---

## Be aware of tolerances

May be a substantial trade-off between accuracy of your solution and speed

--

Common bad practice is to pick a larger tolerance (e.g. `1e-3`) so the problem "works" (e.g. so your big MLE converges)

--

Issue is that `1e-3` might be pretty big for your problem if you haven't checked that your solution is not sensitive to the tolerance

---

## Perturb your initial guesses

**Initial guesses matter**

--

Good ones can improve performance
- E.g. initial guess for next iteration of coefficient estimates should be current iteration estimates

--

Bad ones can give you terrible performance, or wrong answers if your problem isn't perfect
- E.g. bad scaling, not well-conditioned, multiple equilibria






    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
